{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark DataFrames\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful as is [this reference on doing joins in Spark dataframe](http://www.learnbymarketing.com/1100/pyspark-joins-by-example/).\n",
    "\n",
    "The [DataBricks company has one of the better reference manuals for PySpark](https://docs.databricks.com/spark/latest/dataframes-datasets/index.html) -- they show you how to perform numerous common data operations such as joins, aggregation operations following `groupBy` and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following aggregation functions may be useful -- [these can be used to aggregate results of `groupby` operations](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html#example-aggregations-using-agg-and-countdistinct). More documentation is at the [PySpark SQL Functions manual](https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#module-pyspark.sql.functions). Feel free to use other functions from that library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our session as described in the tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Lab4-Dataframe\") \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the citations and patents data and check that the data makes sense. Note that unlike in the RDD solution, the data is automatically inferred to be Integer() types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = spark.read.load('cite75_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "| CITING|  CITED|\n",
      "+-------+-------+\n",
      "|3858241| 956203|\n",
      "|3858241|1324234|\n",
      "|3858241|3398406|\n",
      "|3858241|3557384|\n",
      "|3858241|3634889|\n",
      "+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citations.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents = spark.read.load('apat63_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| PATENT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|3070801| 1963| 1096|   NULL|     BE|   NULL|    NULL|      1|  NULL|   269|  6|    69| NULL|       1|    NULL|    0.0|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070802| 1963| 1096|   NULL|     US|     TX|    NULL|      1|  NULL|     2|  6|    63| NULL|       0|    NULL|   NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070803| 1963| 1096|   NULL|     US|     IL|    NULL|      1|  NULL|     2|  6|    63| NULL|       9|    NULL| 0.3704|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070804| 1963| 1096|   NULL|     US|     OH|    NULL|      1|  NULL|     2|  6|    63| NULL|       3|    NULL| 0.6667|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070805| 1963| 1096|   NULL|     US|     CA|    NULL|      1|  NULL|     2|  6|    63| NULL|       1|    NULL|    0.0|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patents.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+------------+\n",
      "|CITING |CITED  |CITED_STATE|CITING_STATE|\n",
      "+-------+-------+-----------+------------+\n",
      "|3858258|1540798|NULL       |CA          |\n",
      "|3858258|1331793|NULL       |CA          |\n",
      "|3858527|3638586|CA         |NULL        |\n",
      "|3858527|924225 |NULL       |NULL        |\n",
      "|3858527|2444326|NULL       |NULL        |\n",
      "|3858527|3699902|OH         |NULL        |\n",
      "|3858527|2967080|NULL       |NULL        |\n",
      "|3858527|3602157|TX         |NULL        |\n",
      "|3858527|2705120|NULL       |NULL        |\n",
      "|3858560|957631 |NULL       |IN          |\n",
      "+-------+-------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Prep + join states onto citations ---\n",
    "# Goal: create the intermediate table:\n",
    "#   (CITING, CITED, CITED_STATE, CITING_STATE)\n",
    "# We drop null/blank POSTATE up front so comparisons later are clean.\n",
    "# Left joins are intentional: not every cited/citing patent has state info.\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Clean mapping: patent -> state\n",
    "pat_states_clean = (\n",
    "    patents\n",
    "    .select(\"PATENT\", \"POSTATE\")\n",
    "    .filter(col(\"POSTATE\").isNotNull() & (col(\"POSTATE\") != \"\"))\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "# Attach cited patent state\n",
    "cited_state = (\n",
    "    citations\n",
    "    .join(\n",
    "        pat_states_clean.withColumnRenamed(\"PATENT\", \"CITED\"),\n",
    "        on=\"CITED\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .select(\"CITING\", \"CITED\", col(\"POSTATE\").alias(\"CITED_STATE\"))\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "# Attach citing patent state (now we have both sides)\n",
    "both_states = (\n",
    "    cited_state\n",
    "    .join(\n",
    "        pat_states_clean.withColumnRenamed(\"PATENT\", \"CITING\"),\n",
    "        on=\"CITING\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .select(\"CITING\", \"CITED\", \"CITED_STATE\", col(\"POSTATE\").alias(\"CITING_STATE\"))\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "# Quick peek just to confirm columns look right (nulls are expected)\n",
    "both_states.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare patent state data and attach it to citations\n",
    "\n",
    "In this step, I prepare the data needed to identify same-state patent citations.  \n",
    "I begin by creating a clean mapping from patent number to state (`PATENT â†’ POSTATE`), keeping only patents with valid state information. This helps avoid issues later when comparing states or counting citations.\n",
    "\n",
    "Next, I join this state information onto the citation dataset twice. The first join attaches the state of the **cited** patent, and the second join attaches the state of the **citing** patent. Left joins are used intentionally because not all patents appear in both datasets and missing state values are expected.\n",
    "\n",
    "The result of this step is an intermediate table containing the citing patent, the cited patent, and the state associated with each. This table is used directly in the next step to identify and count same-state citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+\n",
      "|PATENT |POSTATE|SAME_STATE|\n",
      "+-------+-------+----------+\n",
      "|5959466|CA     |125       |\n",
      "|5983822|TX     |103       |\n",
      "|6008204|CA     |100       |\n",
      "|5952345|CA     |98        |\n",
      "|5958954|CA     |96        |\n",
      "|5998655|CA     |96        |\n",
      "|5936426|CA     |94        |\n",
      "|5739256|CA     |90        |\n",
      "|5913855|CA     |90        |\n",
      "|5925042|CA     |90        |\n",
      "+-------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Count same-state citations + join back onto patents + top 10 ---\n",
    "# Same-state citation = both states exist AND match.\n",
    "# Then count per CITING patent, attach as SAME_STATE (missing -> 0),\n",
    "# and print the top 10 patents by SAME_STATE (descending).\n",
    "\n",
    "from pyspark.sql.functions import count, lit, coalesce\n",
    "\n",
    "same_state_counts = (\n",
    "    both_states\n",
    "    .filter(col(\"CITED_STATE\").isNotNull() & col(\"CITING_STATE\").isNotNull())\n",
    "    .filter(col(\"CITED_STATE\") == col(\"CITING_STATE\"))\n",
    "    .groupBy(\"CITING\")\n",
    "    .agg(count(lit(1)).alias(\"SAME_STATE\"))\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "patents_aug = (\n",
    "    patents\n",
    "    .join(\n",
    "        same_state_counts,\n",
    "        patents[\"PATENT\"].cast(\"int\") == same_state_counts[\"CITING\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .drop(\"CITING\")\n",
    "    .withColumn(\"SAME_STATE\", coalesce(col(\"SAME_STATE\"), lit(0)))\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "top10 = (\n",
    "    patents_aug\n",
    "    .filter(col(\"POSTATE\").isNotNull() & (col(\"POSTATE\") != \"\"))  # keep US-state patents\n",
    "    .select(\"PATENT\", \"POSTATE\", \"SAME_STATE\")\n",
    "    .orderBy(col(\"SAME_STATE\").desc(), col(\"PATENT\").asc())\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "top10.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Count same-state citations and identify the top patents\n",
    "\n",
    "In this step, I compute the main value required for the assignment: the number of same-state citations for each patent. A same-state citation is defined as a citation where both the citing patent and the cited patent have state information and originate from the same state.\n",
    "\n",
    "Using the intermediate table from the previous step, I first filter out any rows where state information is missing. I then keep only the cases where the cited and citing states match. These filtered rows are grouped by the citing patent and counted to determine how many same-state citations each patent has.\n",
    "\n",
    "This count is joined back onto the original patent dataset as a new column called `SAME_STATE`. Patents without any same-state citations are assigned a value of zero. Finally, the results are sorted in descending order to identify the top ten patents with the highest number of same-state citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "|PATENT |GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|SAME_STATE|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "|5959466|1999 |14515|1997   |US     |CA     |5310    |2      |NULL  |326   |4  |46    |159  |0       |1.0     |NULL   |0.6186  |NULL    |4.8868  |0.0455  |0.044   |NULL    |NULL    |125       |\n",
      "|5983822|1999 |14564|1998   |US     |TX     |569900  |2      |NULL  |114   |5  |55    |200  |0       |0.995   |NULL   |0.7201  |NULL    |12.45   |0.0     |0.0     |NULL    |NULL    |103       |\n",
      "|6008204|1999 |14606|1998   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |121  |0       |1.0     |NULL   |0.7415  |NULL    |5.0     |0.0085  |0.0083  |NULL    |NULL    |100       |\n",
      "|5952345|1999 |14501|1997   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |118  |0       |1.0     |NULL   |0.7442  |NULL    |5.1102  |0.0     |0.0     |NULL    |NULL    |98        |\n",
      "|5958954|1999 |14515|1997   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |116  |0       |1.0     |NULL   |0.7397  |NULL    |5.181   |0.0     |0.0     |NULL    |NULL    |96        |\n",
      "|5998655|1999 |14585|1998   |US     |CA     |NULL    |1      |NULL  |560   |1  |14    |114  |0       |1.0     |NULL   |0.7387  |NULL    |5.1667  |NULL    |NULL    |NULL    |NULL    |96        |\n",
      "|5936426|1999 |14466|1997   |US     |CA     |5310    |2      |NULL  |326   |4  |46    |178  |0       |1.0     |NULL   |0.58    |NULL    |11.2303 |0.0765  |0.073   |NULL    |NULL    |94        |\n",
      "|5913855|1999 |14417|1997   |US     |CA     |733846  |2      |NULL  |606   |3  |32    |242  |0       |1.0     |NULL   |0.7403  |NULL    |8.3595  |0.0     |0.0     |NULL    |NULL    |90        |\n",
      "|5739256|1998 |13983|1995   |US     |CA     |70060   |2      |15    |528   |1  |15    |453  |0       |1.0     |NULL   |0.8232  |NULL    |15.1104 |0.1124  |0.1082  |NULL    |NULL    |90        |\n",
      "|5925042|1999 |14445|1997   |US     |CA     |733846  |2      |NULL  |606   |3  |32    |242  |0       |1.0     |NULL   |0.7382  |NULL    |8.3471  |0.0     |0.0     |NULL    |NULL    |90        |\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Reference-style output ---\n",
    "# Show the full patent record with SAME_STATE appended at the end.\n",
    "# This matches the format shown in the lab README screenshot\n",
    "# (all original patent columns + SAME_STATE, sorted by SAME_STATE).\n",
    "\n",
    "patents_aug_ref = patents_aug.select(*patents.columns, \"SAME_STATE\")\n",
    "\n",
    "patents_aug_ref \\\n",
    "    .orderBy(col(\"SAME_STATE\").desc()) \\\n",
    "    .show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final output (DataFrame solution)\n",
    "\n",
    "My final solution uses the PySpark **DataFrame** method. I attach state information to citations (for both the cited and citing patents), count how many citations stay within the same state, and then add that count back onto the patent table as `SAME_STATE` (missing values become 0). This final output prints the top 10 patents with the highest `SAME_STATE` values in the same wide-table format as the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
